{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a07e7793-b8f5-44f4-aded-5562f633271a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import tempfile\n",
    "from io import BytesIO\n",
    "from typing import Tuple, Optional\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import gradio as gr\n",
    "from PIL import Image\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "846acaaf-61fc-4b99-9b68-59e6ee2c122a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(override=True)\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "MODEL_TEXT = \"gpt-4o-mini\"        # Text chat\n",
    "MODEL_STT = \"whisper-1\"           # Speech-to-text\n",
    "MODEL_TTS = \"tts-1\"               # Text-to-speech\n",
    "MODEL_IMG = \"dall-e-3\"            # Image generation\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af245fb4-33fb-4acf-bb89-485fc8da48ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = (\n",
    "    \"You are FriendlyAfrica, a helpful, concise airline-style assistant focused on African cities. \"\n",
    "    \"Keep answers short (1–2 sentences), accurate, and say when you don't know. \"\n",
    "    \"If a user mentions a city, consider using available tools to fetch a quick, curated snapshot.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59c380d4-5738-43b7-8f32-800063df4288",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_facts = {\n",
    "    \"lagos\": {\n",
    "        \"country\": \"Nigeria\",\n",
    "        \"population_approx\": \"15–20M (metro)\",\n",
    "        \"highlights\": [\"Eko Atlantic\", \"Lekki Conservation Centre\", \"National Theatre\"],\n",
    "        \"blurb\": \"Lagos is West Africa’s commercial hub and one of the world’s fastest-growing cities.\"\n",
    "    },\n",
    "    \"nairobi\": {\n",
    "        \"country\": \"Kenya\",\n",
    "        \"population_approx\": \"4–5M (city)\",\n",
    "        \"highlights\": [\"Nairobi National Park\", \"Karen Blixen Museum\", \"Giraffe Centre\"],\n",
    "        \"blurb\": \"Nairobi blends urban energy with wildlife at its doorstep.\"\n",
    "    },\n",
    "    \"cape town\": {\n",
    "        \"country\": \"South Africa\",\n",
    "        \"population_approx\": \"4–5M (metro)\",\n",
    "        \"highlights\": [\"Table Mountain\", \"V&A Waterfront\", \"Cape Point\"],\n",
    "        \"blurb\": \"Cape Town is famed for dramatic landscapes, beaches, and wine country.\"\n",
    "    },\n",
    "    \"cairo\": {\n",
    "        \"country\": \"Egypt\",\n",
    "        \"population_approx\": \"20–22M (metro)\",\n",
    "        \"highlights\": [\"Pyramids of Giza\", \"Egyptian Museum\", \"Khan el-Khalili\"],\n",
    "        \"blurb\": \"Cairo sits along the Nile and anchors millennia of history.\"\n",
    "    },\n",
    "    \"accra\": {\n",
    "        \"country\": \"Ghana\",\n",
    "        \"population_approx\": \"2–3M (city)\",\n",
    "        \"highlights\": [\"Jamestown\", \"Kwame Nkrumah Mausoleum\", \"Labadi Beach\"],\n",
    "        \"blurb\": \"Accra offers coastal vibes, art, and growing culinary scenes.\"\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae6484b2-ecb7-45de-9078-a67537697c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_city_info(city: str) -> dict:\n",
    "    \"\"\"\n",
    "    Return a compact, curated snapshot for an African city from a small local dataset.\n",
    "    \"\"\"\n",
    "    c = (city or \"\").strip().lower()\n",
    "    if c in city_facts:\n",
    "        return {\"city\": city, **city_facts[c]}\n",
    "    return {\"city\": city, \"blurb\": \"Unknown\", \"country\": \"Unknown\", \"population_approx\": \"Unknown\", \"highlights\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3b9a295-b9ca-4f5b-99bf-eced7c7b0426",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_info_function = {\n",
    "    \"name\": \"get_city_info\",\n",
    "    \"description\": \"Get a compact snapshot for the named African city (country, approximate population, highlights, and a short blurb).\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"city\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The city name, e.g., 'Lagos', 'Nairobi', 'Cairo'.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"city\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}\n",
    "\n",
    "tools = [{\"type\": \"function\", \"function\": city_info_function}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c752ccb-f215-4f8a-b139-5d276ee4b083",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_tool_call(message) -> Tuple[dict, str]:\n",
    "    \"\"\"\n",
    "    Handle the first tool call suggested by the model.\n",
    "    \"\"\"\n",
    "    tool_call = message.tool_calls[0]\n",
    "    fn = tool_call.function\n",
    "    args = json.loads(fn.arguments) if fn.arguments else {}\n",
    "    city = args.get(\"city\", \"\")\n",
    "    data = get_city_info(city)\n",
    "    response = {\n",
    "        \"role\": \"tool\",\n",
    "        \"content\": json.dumps(data),\n",
    "        \"tool_call_id\": tool_call.id\n",
    "    }\n",
    "    return response, city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "300fe54b-f022-4508-a6ca-254d9c2ca149",
   "metadata": {},
   "outputs": [],
   "source": [
    "def artist(city: str) -> Optional[Image.Image]:\n",
    "    if not city:\n",
    "        return None\n",
    "    prompt = (\n",
    "        f\"An inviting travel poster of {city} in Africa, showing iconic landmarks and local vibe, \"\n",
    "        f\"in a vibrant pop-art style, high detail.\"\n",
    "    )\n",
    "    image_response = openai.images.generate(\n",
    "        model=MODEL_IMG,\n",
    "        prompt=prompt,\n",
    "        size=\"1024x1024\",\n",
    "        n=1,\n",
    "        response_format=\"b64_json\",\n",
    "    )\n",
    "    image_base64 = image_response.data[0].b64_json\n",
    "    image_data = base64.b64decode(image_base64)\n",
    "    return Image.open(BytesIO(image_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cafd8c46-5a48-4db3-845d-a044cd48cf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe(filepath: str) -> str:\n",
    "    \"\"\"\n",
    "    Transcribe a local audio file path to text using Whisper.\n",
    "    Acceptable formats include WAV/MP3/M4A/WEBM etc.\n",
    "    \"\"\"\n",
    "    if not filepath:\n",
    "        return \"\"\n",
    "    with open(filepath, \"rb\") as f:\n",
    "        tr = openai.audio.transcriptions.create(\n",
    "            model=MODEL_STT,\n",
    "            file=f,\n",
    "        )\n",
    "    return tr.text or \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fba8b7e-5484-4a12-b6af-94649d0ea577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesize_tts(text: str, voice: str = \"alloy\") -> str:\n",
    "    \"\"\"\n",
    "    Synthesize speech to a temporary mp3 file and return the path.\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    resp = openai.audio.speech.create(\n",
    "        model=MODEL_TTS,\n",
    "        voice=voice,\n",
    "        input=text\n",
    "    )\n",
    "    tmp = tempfile.NamedTemporaryFile(suffix=\".mp3\", delete=False)\n",
    "    tmp.write(resp.content)\n",
    "    tmp.flush()\n",
    "    tmp.close()\n",
    "    return tmp.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0177454d-15bb-4536-ba51-c0aab49b97f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_once(user_message: str, history_messages: list, enable_tools: bool = True) -> Tuple[str, Optional[Image.Image], Optional[str]]:\n",
    "    \"\"\"\n",
    "    One LLM turn, with optional function-calling tool and optional image generation.\n",
    "    Returns: reply_text, image_or_None, city_name_or_None_detected_in_tool\n",
    "    \"\"\"\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history_messages + [{\"role\": \"user\", \"content\": user_message}]\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "        model=MODEL_TEXT,\n",
    "        messages=messages,\n",
    "        tools=tools if enable_tools else None\n",
    "    )\n",
    "\n",
    "    img = None\n",
    "    chosen_city = None\n",
    "\n",
    "    if enable_tools and response.choices[0].finish_reason == \"tool_calls\":\n",
    "        message = response.choices[0].message\n",
    "        tool_response, city = handle_tool_call(message)\n",
    "        chosen_city = city\n",
    "        messages.append(message)\n",
    "        messages.append(tool_response)\n",
    "        response = openai.chat.completions.create(model=MODEL_TEXT, messages=messages)\n",
    "\n",
    "    reply = response.choices[0].message.content\n",
    "    return reply, img, chosen_city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "792f2fa8-3c99-4d67-9e63-360ed30f6bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ui():\n",
    "    with gr.Blocks(title=\"FriendlyAfrica: Multimodal AI for African Cities\") as demo:\n",
    "        gr.Markdown(\"## FriendlyAfrica: Ask about African cities via text or voice\")\n",
    "        with gr.Row():\n",
    "            chatbot = gr.Chatbot(label=\"FriendlyAfrica\", type=\"messages\", height=400)\n",
    "            with gr.Column():\n",
    "                tts_audio = gr.Audio(label=\"Assistant Voice\", type=\"filepath\", autoplay=True)\n",
    "                city_image = gr.Image(label=\"City Image (optional)\", interactive=False)\n",
    "\n",
    "        with gr.Row():\n",
    "            with gr.Column(scale=3):\n",
    "                text_in = gr.Textbox(placeholder=\"Type your question (e.g., 'Tell me about Nairobi') and press Enter\", show_label=False)\n",
    "                mic_in = gr.Audio(sources=[\"microphone\"], type=\"filepath\", label=\"Or ask by voice\")\n",
    "                with gr.Row():\n",
    "                    btn_transcribe_and_ask = gr.Button(\"Transcribe & Ask (from mic)\", variant=\"primary\")\n",
    "                    btn_clear = gr.Button(\"Clear\")\n",
    "\n",
    "            with gr.Column(scale=2):\n",
    "                enable_tts = gr.Checkbox(value=True, label=\"Speak answers (TTS)\")\n",
    "                voice = gr.Radio(choices=[\"alloy\", \"onyx\"], value=\"alloy\", label=\"Voice\")\n",
    "                enable_image = gr.Checkbox(value=False, label=\"Generate city image if a city is detected\")\n",
    "                enable_tools = gr.Checkbox(value=True, label=\"Use curated city facts tool\", info=\"Calls get_city_info when helpful\")\n",
    "\n",
    "        state = gr.State([])  # LLM message history (list of dicts)\n",
    "\n",
    "        def on_text_submit(user_msg, hist, do_tts, voice_opt, do_image, do_tools):\n",
    "            user_msg = (user_msg or \"\").strip()\n",
    "            if not user_msg:\n",
    "                return gr.update(), None, None, \"\"  # no change\n",
    "\n",
    "            reply, img, city = chat_once(user_msg, hist or [], enable_tools=bool(do_tools))\n",
    "            new_hist = (hist or []) + [{\"role\": \"user\", \"content\": user_msg}, {\"role\": \"assistant\", \"content\": reply}]\n",
    "\n",
    "            audio_path = \"\"\n",
    "            if do_tts:\n",
    "                audio_path = synthesize_tts(reply, voice=voice_opt or \"alloy\")\n",
    "\n",
    "            # Image generation\n",
    "            img_out = None\n",
    "            if do_image and city:\n",
    "                try:\n",
    "                    img_out = artist(city)\n",
    "                except Exception:\n",
    "                    img_out = None\n",
    "\n",
    "            return new_hist, img_out, audio_path, \"\"\n",
    "\n",
    "        def on_transcribe_and_ask(mic_path, hist, do_tts, voice_opt, do_image, do_tools):\n",
    "            # STT\n",
    "            user_msg = transcribe(mic_path) if mic_path else \"\"\n",
    "            if not user_msg:\n",
    "                return gr.update(), None, None, \"\"\n",
    "\n",
    "            reply, img, city = chat_once(user_msg, hist or [], enable_tools=bool(do_tools))\n",
    "            new_hist = (hist or []) + [{\"role\": \"user\", \"content\": user_msg}, {\"role\": \"assistant\", \"content\": reply}]\n",
    "\n",
    "            audio_path = \"\"\n",
    "            if do_tts:\n",
    "                audio_path = synthesize_tts(reply, voice=voice_opt or \"alloy\")\n",
    "\n",
    "            img_out = None\n",
    "            if do_image and city:\n",
    "                try:\n",
    "                    img_out = artist(city)\n",
    "                except Exception:\n",
    "                    img_out = None\n",
    "\n",
    "            return new_hist, img_out, audio_path, \"\"\n",
    "\n",
    "        def on_clear():\n",
    "            return [], None, None, \"\"\n",
    "\n",
    "        # Wire events\n",
    "        text_in.submit(\n",
    "            on_text_submit,\n",
    "            inputs=[text_in, state, enable_tts, voice, enable_image, enable_tools],\n",
    "            outputs=[chatbot, city_image, tts_audio, text_in],\n",
    "        )\n",
    "\n",
    "        btn_transcribe_and_ask.click(\n",
    "            on_transcribe_and_ask,\n",
    "            inputs=[mic_in, state, enable_tts, voice, enable_image, enable_tools],\n",
    "            outputs=[chatbot, city_image, tts_audio, text_in],\n",
    "        )\n",
    "\n",
    "        btn_clear.click(\n",
    "            on_clear,\n",
    "            inputs=[],\n",
    "            outputs=[chatbot, city_image, tts_audio, text_in],\n",
    "        )\n",
    "\n",
    "    return demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49f82924-5e00-4d0c-b959-9b60f6aedcdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    demo = build_ui()\n",
    "    demo.launch()\n",
    "except Exception as e:\n",
    "    print(\"Failed to launch UI:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a65ecf9-8525-4085-86e3-5ecbb8d726a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
